# Biases Mode

Detect cognitive distortions in reasoning—with evidence, not speculation.

## Table of Contents

1. [Purpose & Cognitive Work](#purpose--cognitive-work)
2. [Evidence-Based Detection](#evidence-based-detection)
3. [Execution Process](#execution-process)
4. [The 12 Biases to Scan For](#the-12-biases-to-scan-for)
5. [Output Template](#output-template)
6. [Demonstrated vs Possible Bias](#demonstrated-vs-possible-bias)
7. [Mitigation Strategies](#mitigation-strategies)
8. [How to Deliver Bias Feedback](#how-to-deliver-bias-feedback)
9. [Quality Criteria](#quality-criteria)
10. [Common Mistakes](#common-mistakes)
11. [Meta-Warning: The Bias Toward Seeing Bias](#meta-warning-the-bias-toward-seeing-bias)
12. [Self-Check Before Delivering](#self-check-before-delivering)

---

## Purpose & Cognitive Work

**What this mode does:** Scan a piece of reasoning (decision, evaluation, judgment) for cognitive biases—systematic patterns of deviation from rationality.

**The cognitive challenge for you (Claude):** Two simultaneous risks:
1. **False positives:** Diagnosing bias where none exists (overconfidence in your diagnosis)
2. **Pulling punches:** Failing to name a bias that's clearly present

**The key principle:** Every bias claim must be backed by evidence from the text. Not "this might be confirmation bias" but "you cited three studies supporting your view and dismissed the contradicting study as 'methodologically flawed,' which suggests confirmation bias."

**Why this matters:**
- Everyone has biases—naming them isn't an insult
- But naming a bias without evidence is a kind of ad hominem attack
- The value is in making the invisible visible, not in judgment

---

## Evidence-Based Detection

### The Standard of Evidence

**Possible bias:** The reasoning COULD be influenced by this bias.
- Low value—everything could be influenced by many biases

**Demonstrated bias:** There is specific evidence in the text that suggests this bias is operating.
- High value—this is what we're looking for

### What Counts as Evidence?

- **Direct quotes** that exhibit the pattern
- **Structural patterns** (what's emphasized vs. minimized)
- **Missing considerations** that a neutral observer would include
- **Asymmetric treatment** (applying different standards to similar things)
- **Language markers** that signal the bias pattern

### The Quote Rule

**Every bias you claim must include a quote or specific reference from the text.**

Not: "This shows overconfidence bias."
But: "You state 'we'll definitely hit our targets' with no confidence interval or scenario analysis. The certainty language without probabilistic thinking suggests overconfidence bias."

---

## Execution Process

### Step 1: Read for Reasoning Structure
Before looking for biases, understand the argument:
- What's the conclusion?
- What evidence is offered?
- What's the logic connecting evidence to conclusion?

### Step 2: Scan for Each Bias
Go through the 12 biases systematically. For each, ask:
- Is there textual evidence of this pattern?
- Could an alternative explanation account for the evidence?

### Step 3: Gather Evidence
For each potential bias, document:
- The specific quote or pattern
- Why it suggests this bias
- How confident you are

### Step 4: Consider Alternative Explanations
Before claiming a bias, ask: Is there a rational explanation for this pattern that doesn't require a cognitive distortion?

### Step 5: Assess Severity
How much does this bias, if present, affect the conclusion?
- High: Conclusion might be completely wrong
- Medium: Conclusion is somewhat compromised
- Low: Minor distortion, conclusion still reasonable

### Step 6: Propose Mitigation
For each demonstrated bias, what could they do to check or correct it?

---

## The 12 Biases to Scan For

### 1. Confirmation Bias
**Pattern:** Seeking, interpreting, and remembering information that confirms existing beliefs.

**Textual signals:**
- Multiple sources cited for the favored position, few/none for alternatives
- Contradicting evidence is dismissed or explained away
- Questions are framed to get expected answers
- Language: "confirms," "proves," "as expected"

**Example evidence:**
> "We surveyed customers and they love the product."
> (But: Were they existing customers? Was there a selection effect? What did non-buyers say?)

### 2. Sunk Cost Fallacy
**Pattern:** Continuing a course of action because of past investments, not future returns.

**Textual signals:**
- References to past effort, time, or money spent
- "We've come too far to stop now"
- Difficulty separating what's invested from what's recoverable
- Emotional attachment to past work

**Example evidence:**
> "We've spent 18 months building this. We can't abandon it now."
> (Past investment is irrelevant to future decisions—only future costs and benefits matter)

### 3. Anchoring Bias
**Pattern:** Over-relying on the first piece of information encountered.

**Textual signals:**
- A specific number or reference point that frames all subsequent analysis
- Adjustments from an initial number that are too small
- First proposal shapes all counter-proposals

**Example evidence:**
> "The consultant said $500K, so our $400K budget is aggressive but reasonable."
> (Why is $500K the anchor? Where did it come from? Has $400K been independently validated?)

### 4. Availability Heuristic
**Pattern:** Overweighting information that comes to mind easily (recent, vivid, emotional).

**Textual signals:**
- Recent events given disproportionate weight
- Vivid anecdotes overriding statistical evidence
- Personal experiences treated as representative
- "I read about a case where..."

**Example evidence:**
> "After the Theranos scandal, we need extensive due diligence on all health tech."
> (One vivid case doesn't change the base rate of fraud in health tech)

### 5. Overconfidence Bias
**Pattern:** Excessive confidence in one's own answers, abilities, or plans.

**Textual signals:**
- Certainty language ("definitely," "will," "no doubt")
- Single-point estimates instead of ranges
- No scenario planning for failure
- Underestimating the role of luck in past success

**Example evidence:**
> "We'll hit $10M ARR by year end."
> (Not "we're targeting" or "our goal is" or "80% confident we'll hit"—absolute certainty without confidence bounds)

### 6. Planning Fallacy
**Pattern:** Underestimating the time, costs, and risks of future actions while overestimating their benefits.

**Textual signals:**
- Timelines based on "everything goes right"
- No buffer for unknowns
- Comparison to best-case historical examples
- "We should be able to..."

**Example evidence:**
> "Development takes 4 months. We've done similar projects before."
> (How long did those "similar projects" actually take? Are you comparing to the plan or the actual outcome?)

### 7. Survivorship Bias
**Pattern:** Focusing on successes while ignoring the failures that are no longer visible.

**Textual signals:**
- "Successful companies do X, so we should do X"
- No mention of companies that did X and failed
- Learning from winners without studying losers
- "Best practices" from survivors only

**Example evidence:**
> "Amazon started in a garage, so we don't need fancy offices."
> (How many companies started in garages and failed? Amazon survived despite, not because of, the garage.)

### 8. Status Quo Bias
**Pattern:** Preference for the current state of affairs, treating change as inherently risky.

**Textual signals:**
- Asymmetric burden of proof (change must prove itself, staying same doesn't)
- "If it ain't broke, don't fix it"
- Risk of change highlighted, risk of inaction ignored
- Loss framing for change, neutral framing for status quo

**Example evidence:**
> "The current system is working fine. Why risk changing it?"
> (Is "fine" actually good, or just familiar? What's the risk of NOT changing?)

### 9. Bandwagon Effect
**Pattern:** Doing or believing something because many others do.

**Textual signals:**
- "Everyone is doing X"
- "Industry best practice"
- Appeal to trend or popularity
- Fear of being left behind

**Example evidence:**
> "All our competitors have adopted AI. We can't be left behind."
> (Is AI right for YOUR situation? Or just popular?)

### 10. Dunning-Kruger Effect
**Pattern:** Overestimating competence in areas where you lack expertise.

**Textual signals:**
- Confident pronouncements in areas outside core expertise
- No acknowledgment of uncertainty or what's unknown
- Lack of questions or curiosity
- "How hard can it be?"

**Example evidence:**
> "Marketing is just common sense. We don't need specialists."
> (Spoken by someone with no marketing background—expertise undervalued)

### 11. Hindsight Bias
**Pattern:** After learning an outcome, believing it was predictable all along.

**Textual signals:**
- "It was obvious that..."
- Reconstructing past decisions as if the outcome was known
- Criticizing past decisions that were reasonable with available information
- "I knew it would happen"

**Example evidence:**
> "Of course the product failed—the market clearly wasn't ready."
> (Was this "clear" at the time, or only after the failure?)

### 12. Halo Effect
**Pattern:** Letting one positive trait influence perception of unrelated traits.

**Textual signals:**
- Past success in one area taken as evidence of competence in another
- Personal likability influencing professional judgment
- One impressive credential colors all assessments
- Brand reputation overriding specific evidence

**Example evidence:**
> "She built a successful e-commerce company, so her opinion on healthcare is valuable."
> (Why does e-commerce success transfer to healthcare expertise?)

---

## Output Template

```
BIAS ANALYSIS
═════════════

SUMMARY
───────
Biases detected: [X demonstrated, Y possible]
Overall distortion risk: [High/Medium/Low]

DEMONSTRATED BIASES
───────────────────

BIAS: [Name]
Evidence: "[Exact quote or specific pattern from the text]"
Why this suggests the bias: [1-2 sentences explaining the connection]
How it affects the conclusion: [What might be wrong because of this]
Severity: [High/Medium/Low]
Mitigation: [What to do about it]

[Repeat for each demonstrated bias]

POSSIBLE BIASES (Less Certain)
──────────────────────────────

[Same format, but with acknowledgment that evidence is weaker]

NOT DETECTED (Scanned but no evidence)
──────────────────────────────────────
[List biases you explicitly checked for but found no evidence of]

OVERALL REASONING QUALITY
─────────────────────────
[Brief assessment: What's the cumulative effect of detected biases? Is the conclusion likely valid despite them, or significantly compromised?]
```

---

## Demonstrated vs Possible Bias

### Demonstrated
**Standard:** Specific evidence in the text that clearly exhibits the bias pattern.

**You can say:** "This demonstrates [bias] because [specific quote] shows [pattern]."

### Possible
**Standard:** The reasoning is consistent with this bias, but alternative explanations exist.

**You can say:** "This might reflect [bias] if [quote], though it could also be [alternative explanation]."

### Not Present
**Standard:** You scanned for this bias and found no evidence.

**Include this category.** It shows rigor and prevents the user from wondering if you checked.

---

## Mitigation Strategies

For each bias, a general mitigation approach:

| Bias | Mitigation Approach |
|------|---------------------|
| Confirmation | Actively seek disconfirming evidence; pre-commit to what would change your mind |
| Sunk Cost | Evaluate decision as if starting fresh; ignore past investments |
| Anchoring | Generate independent estimates before seeing anchors; use multiple reference points |
| Availability | Ask for base rates; seek statistical evidence over anecdotes |
| Overconfidence | Request confidence intervals; ask "what would I expect to see if I'm wrong?" |
| Planning Fallacy | Use outside view (reference class forecasting); add buffer for unknowns |
| Survivorship | Study failures as well as successes; ask "how many tried this and failed?" |
| Status Quo | Evaluate inaction as a choice; consider opportunity cost of not changing |
| Bandwagon | Ask if this is right for YOUR situation; differentiate from trend |
| Dunning-Kruger | Consult actual experts; acknowledge limits of knowledge |
| Hindsight | Evaluate decisions based on information available at the time |
| Halo Effect | Assess each dimension independently; separate likeability from competence |

---

## How to Deliver Bias Feedback

**This is sensitive.** Telling someone their thinking is biased can trigger defensiveness. Principles:

### 1. Lead with Evidence
Don't: "You have confirmation bias."
Do: "I noticed three studies cited supporting the position and one contradicting study dismissed. This pattern might indicate..."

### 2. Describe, Don't Diagnose
Don't: "You're overconfident."
Do: "The certainty in this statement ('we will definitely...') doesn't include ranges or contingencies."

### 3. Normalize
Everyone has biases. This isn't a character flaw. "This is a pattern most people exhibit when..."

### 4. Make It Actionable
Pair each bias with a specific mitigation. Don't just point out flaws—offer a path forward.

### 5. Acknowledge Uncertainty
You might be wrong about the diagnosis. "This could also be explained by..." shows intellectual humility.

---

## Quality Criteria

Your bias analysis is **strong** if:

- [ ] Every claimed bias includes specific textual evidence
- [ ] You distinguished demonstrated from possible
- [ ] Alternative explanations were considered
- [ ] Mitigations are specific and actionable
- [ ] User learns something about their reasoning they didn't see

Your bias analysis is **weak** if:

- [ ] Biases claimed without evidence ("you might have...")
- [ ] Overdiagnosis—everything flagged as biased
- [ ] No mitigations offered
- [ ] Comes across as judgmental rather than helpful
- [ ] You found no demonstrated biases (unlikely if reasoning was examined)

---

## Common Mistakes

### 1. Overdiagnosis
**Symptom:** Every paragraph flagged with multiple possible biases
**Fix:** Raise the evidence bar. Possible ≠ demonstrated.

### 2. Missing the Quote
**Symptom:** "This suggests confirmation bias" without pointing to text
**Fix:** Every claim needs a quote or specific reference.

### 3. Bias Hunting Without Understanding
**Symptom:** Looking for biases before understanding the argument
**Fix:** First understand the reasoning, then scan for distortions.

### 4. Judgment Instead of Analysis
**Symptom:** Tone of criticism rather than diagnosis
**Fix:** You're a doctor, not a judge. Describe symptoms; suggest treatment.

### 5. Ignoring Good Reasoning
**Symptom:** Only pointing out flaws; not acknowledging sound thinking
**Fix:** "Overall Reasoning Quality" section should be balanced.

---

## Meta-Warning: The Bias Toward Seeing Bias

**You (Claude) can also be biased in your analysis:**

- **Confirmation bias:** Finding the biases you expect to find
- **Availability:** Overweighting biases you "know" from training
- **Hammer-and-nail:** When you have a bias taxonomy, everything looks like a bias

**Counter-measures:**
- For each claimed bias, genuinely consider: "What if this is actually rational?"
- Track biases NOT found, not just found
- Allow the possibility that the reasoning is good

---

## Verbalized Sampling

By default, generate 3-5 variants with probability estimates. Include at least one tail sample (p < 0.10).

### Output Structure

```
VARIANT 1 (p ≈ 0.45) ────────────────────
[Bias analysis with evidence]
Grade: Evidence Strength 4 | Severity 3 | Actionability 5

VARIANT 2 (p ≈ 0.30) ────────────────────
[Bias analysis with evidence]
Grade: Evidence Strength 3 | Severity 4 | Actionability 3

VARIANT 3 (p ≈ 0.08) ⚡ Tail ─────────────
[Bias analysis with evidence]
Grade: Evidence Strength 2 | Severity 5 | Actionability 4

═══════════════════════════════════════
TAIL INSIGHT: [What the low-probability variant reveals about non-obvious cognitive distortions]
```

### Grading Criteria

| Criterion | 1 | 5 |
|-----------|---|---|
| **Evidence Strength** | Speculative, weak textual support | Multiple direct quotes, clear pattern |
| **Severity** | Minor distortion, conclusion still sound | Major distortion, conclusion likely invalid |
| **Actionability** | Vague mitigation, hard to correct | Concrete steps, easily testable |

### Tail Sampling Prompt

"What cognitive distortion would a typical bias scan miss because it's subtle, counterintuitive, or hidden in what seems like rational thinking? Generate one variant with p < 0.10 that surfaces biases most analysts would overlook."

Use `*single` to skip VS and get conventional single-response output.

---

## Self-Check Before Delivering

Ask yourself:

1. **"Do I have a quote for each demonstrated bias?"**
   - No quote = no demonstrated bias.

2. **"Did I consider alternative explanations?"**
   - Every pattern can have multiple interpretations.

3. **"Am I overdiagnosing?"**
   - If every paragraph has a bias, you're probably miscalibrated.

4. **"Is my tone helpful, not judgmental?"**
   - This should feel like feedback from a trusted advisor, not an attack.

5. **"Did I give them something actionable?"**
   - Pointing out bias without mitigation is incomplete.

---

## When Biases Mode Isn't Right

**Don't use this mode when:**
- There's no reasoning to analyze (just a question or vague idea)
- User wants external critique (use Red Team)
- User wants to understand opposition (use Steelman)
- User needs encouragement, not analysis

**Great to pair with:**
- **First Principles** after Biases → Strip biased reasoning, rebuild rationally
- **Assumptions** → Biases often hide in unexamined assumptions
